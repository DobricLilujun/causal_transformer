{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import timm\n",
    "from torchvision.transforms import Compose, Resize, ToTensor, Normalize\n",
    "\n",
    "\n",
    "# Vision Transformer-based Image Restoration Model\n",
    "class ViTImageRestoration(nn.Module):\n",
    "    def __init__(\n",
    "        self, img_size=224, patch_size=16, embed_dim=768, num_heads=12, decoder_dim=512\n",
    "    ):\n",
    "        super(ViTImageRestoration, self).__init__()\n",
    "        # Pretrained Vision Transformer as encoder\n",
    "        self.encoder = timm.create_model(\n",
    "            \"vit_base_patch16_224\", pretrained=True, num_classes=0\n",
    "        )\n",
    "\n",
    "        # Decoder to reconstruct the missing parts\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(\n",
    "                embed_dim,\n",
    "                decoder_dim,\n",
    "                kernel_size=3,\n",
    "                stride=2,\n",
    "                padding=1,\n",
    "                output_padding=1,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(\n",
    "                decoder_dim, 3, kernel_size=3, padding=1\n",
    "            ),  # Reconstruct RGB channels\n",
    "            nn.Tanh(),  # Normalize output to [-1, 1]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convert input into patch embeddings\n",
    "        batch_size, _, h, w = x.size()\n",
    "        x = self.encoder.patch_embed(x)\n",
    "        # Add positional encoding\n",
    "        x = self.encoder.pos_drop(x + self.encoder.pos_embed)\n",
    "        # Pass through Transformer encoder\n",
    "        x = self.encoder.blocks(x)\n",
    "        x = self.encoder.norm(x)\n",
    "\n",
    "        # Reshape for decoder\n",
    "        x = x.permute(0, 2, 1).view(batch_size, -1, int(h / 16), int(w / 16))\n",
    "        # Decode back to image\n",
    "        restored = self.decoder(x)\n",
    "        return restored\n",
    "\n",
    "\n",
    "# Loss function: Combined reconstruction + perceptual loss\n",
    "def loss_function(pred, target):\n",
    "    l1_loss = nn.L1Loss()(pred, target)\n",
    "    return l1_loss\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "def get_transforms(img_size=224):\n",
    "    return Compose(\n",
    "        [\n",
    "            Resize((img_size, img_size)),\n",
    "            ToTensor(),\n",
    "            Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "        ]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
